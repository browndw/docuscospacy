.. _api:

API
===

corpus_analysis
---------------

Functions for analyzing corpus data tagged with DocuScope and CLAWS7.


corpus_analysis.convert_corpus(tm_corpus)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A simple wrapper for converting a tmtoolkit corpus in an nltk-like dictionary of tuples.

    :Parameters: - **tm_corpus** - A tmtoolkit corpus
    :Return: - a dictionary of tuples

corpus_analysis.frequency_table(tok, n_tokens, count_by='pos')
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a count of token frequencies.

    :Parameters: - **tok** - A dictionary of tuples as generated by the `convert_corpus` function
                 - **n_tokens** - A count of total tokens against which to normalize
                 - **count_by** - One of 'pos' or 'ds' for aggregating tokens
 
    :Return:     - a dataframe of absolute frequencies, normalized frequencies (per million tokens) and ranges


corpus_analysis.tags_table(tok, n_tokens, count_by='pos')
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a count of tag frequencies.

    :Parameters: - **tok** - A dictionary of tuples as generated by the `convert_corpus` function
                 - **n_tokens** - A count of total tokens against which to normalize
                 - **count_by** - One of 'pos' or 'ds' for aggregating tokens
 
    :Return:     - a dataframe of absolute frequencies, normalized frequencies (per million tokens) and ranges

corpus_analysis.tags_dtm(tok, count_by='pos')
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    :Parameters: - **tok** - A dictionary of tuples as generated by the `convert_corpus` function
                 - **n_tokens** - A count of total tokens against which to normalize
                 - **count_by** - One of 'pos' or 'ds' for aggregating tokens
 
    :Return:     - a dataframe of absolute tag frequencies for each document

corpus_analysis.ngrams_table(tok, ng_span, n_tokens, count_by='pos')
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    :Parameters: - **tok** - A dictionary of tuples as generated by the `convert_corpus` function
                 - **ng_span** - An integer between 2 and 5 representing the size of the ngrams
                 - **n_tokens** - A count of total tokens against which to normalize
                 - **count_by** - One of 'pos' or 'ds' for aggregating tokens
 
    :Return:     - a dataframe containing a token sequence the length of the span, a tag sequence the length of the span, absolute frequencies, normalized frequencies (per million tokens) and ranges

corpus_analysis.coll_table(tok, node_word, l_span=4, r_span=4, statistic='pmi', count_by='pos', node_tag=None, tag_ignore=False)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    :Parameters: - **tok** - A dictionary of tuples as generated by the `convert_corpus` function
                 - **node_word** - The token around with collocations are measured
                 - **l_span** - An integer between 0 and 9 representing the span to the left of the node word
                 - **r_span** - An integer between 0 and 9 representing the span to the right of the node word
                 - **statistic** - The association measure to be calculated. One of: 'pmi', 'npmi', 'pmi2', 'pmi3'
                 - **count_by** - One of 'pos' or 'ds' for aggregating tokens
                 - **node_tag** - A value specifying the tag of the node word. If the node_word were 'can', a node_tag 'V' would search for can as a verb.
                 - **tag_ignore** - A boolean value indicating whether or not tags should be ignored during analysis.


    :Return:     - a dataframe containing collocate tokens, tags, the absolute frequency the collocate in the corpus, the absolute frequency of the collocate within the designated span, and the association measure.

corpus_analysis.kwic_center_node(tm_corpus, node_word,  ignore_case=True, glob=False)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    :Parameters: - **tm_corpus** - A tmtoolkit corpus
                 - **node_word** - The token (or partial string of interest)
                 - **ignore_case** - If set to 'False', search will be case sensitive
                 - **glob** - If set to 'True', glob-style searching is enabled

    :Return: - a dataframe with the node word in a center column and context columns on either side.

.. note::  The **tmtoolkit** package has its own, useful KWIC functions. Those return a single column with the node word highlighted. This is simple convenience function for generating a 3-column structure with the node word centered for easier filtering and sorting.

corpus_analysis.keyness_table(target_counts, ref_counts, correct=False, tags_only=False)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    :Parameters: - **target_counts** - A table as created by the `frequency_table` function from a target corpus
                 - **ref_counts** - A table as created by the `frequency_table` function from a reference corpus
                 - **correct** - If set to 'True', the Yates correction will be applied to the log-likelihood calculation
                 - **tags_only** - If 'True', it is assumed the frequency tables are of the type produce by the tags_table function

    :Return: - a dataframe of absolute frequencies, normalized frequencies (per million tokens) and ranges for both corpora, as well as keyness values as calculated by log-likelihood and effect size as calculated by Log Ratio.

.. warning:: Be sure that the target and reference corpora are prepared in the same way prior to making a keyness comparison.


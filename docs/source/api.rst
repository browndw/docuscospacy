.. _api:

API
===

corpus_analysis
---------------

Functions for analyzing corpus data tagged with DocuScope and CLAWS7.


corpus_analysis.docuscope_parse(corp: pl.DataFrame, nlp_model: Language, n_process=1, batch_size=25) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Parse a corpus using the 'en_docuso_spacy' model.

    :Parameters: - **corp** - A polars DataFrame conataining a 'doc_id' column and a 'text' column.
    :Parameters: - **nlp_model** - An 'en_docuso_spacy' instance.
    :Parameters: - **n_process** - The number of parallel processes to use during parsing.
    :Parameters: - **n_process** - The batch size to use during parsing.

    :Return:     - a polars DataFrame with, token sequencies identified by both part-of-speech tags and DocuScope tags.


corpus_analysis.frequency_table(tokens_table: pl.DataFrame, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a count of token frequencies.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **count_by** - One of 'pos', 'ds' or 'both' for aggregating tokens
    
    :Return:     - A polars DataFrame of token counts


corpus_analysis.tags_table(tokens_table: pl.DataFrame, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a count of tag frequencies.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **count_by** - One of 'pos', 'ds' or 'both' for aggregating tokens
    
    :Return:     - a polars DataFrame of absolute frequencies, normalized frequencies(per million tokens) and ranges


corpus_analysis.dispersions_table(tokens_table: pl.DataFrame, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a table of dispersion measures.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    
    :Return:     - a polars DataFrame with various dispersion measures.


corpus_analysis.tags_dtm(tokens_table: pl.DataFrame, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a document-term matrix of raw tag counts.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **count_by** - One of 'pos', 'ds' or 'both' for aggregating tokens
    
    :Return:     - a polars DataFrame of absolute tag frequencies for each document


corpus_analysis.ngrams(tokens_table: pl.DataFrame, span=2, min_frequency=10, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a table of ngram frequencies of a specificd length.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **span** - An interger between 2 and 5 representing the size of the ngrams
    :Parameters: - **min_frequency** The minimum count of the ngrams returned
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    
    :Return:     - a polars DataFrame containing a token sequence the length of the span, a tag sequence the length of the span, absolute frequencies, normalized frequencies (per million tokens) and ranges


corpus_analysis.clusters_by_token(tokens_table: pl.DataFrame, node_word: str, node_position=1, span=2, search_type='fixed', count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a table of cluster frequencies searching by tag.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **node_word** - A token to include in the cluster
    :Parameters: - **node_position** - he placement of the node word in the cluster (1, for example, would be on the left)
    :Parameters: - **span** - An interger between 2 and 5 representing the size of the clusters
    :Parameters: - **search_type** - One of 'fixed', 'starts_with', 'ends_with', or 'contains'
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    
    :Return:     - a polars DataFrame containing a token sequence the length of the span, a tag sequence the length of the span, absolute frequencies, normalized frequencies (per million tokens) and ranges


corpus_analysis.clusters_by_tag(tokens_table: pl.DataFrame, tag: str, tag_position=1, span=2, count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a table of cluster frequencies searching by tag.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **tag** - A tag to include in the clusters
    :Parameters: - **tag_position** - The placement of tag in the clusters (1, for example, would be on the left)
    :Parameters: - **span** - An interger between 2 and 5 representing the size of the clusters
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    
    :Return:     - a polars DataFrame containing a token sequence the length of the span, a tag sequence the length of the span, absolute frequencies, normalized frequencies (per million tokens) and ranges


corpus_analysis.kwic_center_node(tokens_table: pl.DataFrame, node_word: str, ignore_case=True, search_type='fixed') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a KWIC table with the node word in the center column.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **node_word** - The token of interest
    :Parameters: - **search_type** - One of 'fixed', 'starts_with', 'ends_with', or 'contains'
    
    :Return:     - A polars DataFrame containing with the node word in a center column and context columns on either side.


corpus_analysis.coll_table(tokens_table: pl.DataFrame, node_word: str, preceding=4, following=4, statistic='npmi', count_by='pos', node_tag=None) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a table of collocations by association measure.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **node_word** - The token around with collocations are measured
    :Parameters: - **preceding** - An integer between 0 and 9 representing the span to the left of the node word
    :Parameters: - **following** - An integer between 0 and 9 representing the span to the right of the node word
    :Parameters: - **statistic** - The association measure to be calculated. One of: 'pmi', 'npmi', 'pmi2', 'pmi3'
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    :Parameters: - **node_tag** - A value specifying the first character or characters of the node word tag. If the node_word were 'can', a node_tag 'V' would search for can as a verb.
    
    :Return:     - a polars DataFrame containing collocate tokens, tags, the absolute frequency the collocate in the corpus, the absolute frequency of the collocate within the span, and the association measure.


corpus_analysis.keyness_table(target_frequencies: pl.DataFrame, reference_frequencies: pl.DataFrame, correct=False, tags_only=False, swap_target=False, threshold=.01):
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Generate a keyness table comparing token frequencies from a taget and a reference corpus

    :Parameters: - **target_frequencies** - A frequency table from a target corpus
    :Parameters: - **reference_frequencies** - A frequency table from a reference corpus
    :Parameters: - **correct** - If True, apply the Yates correction to the log-likelihood calculation
    :Parameters: - **tags_only** - If True, it is assumed the frequency tables are of the type produced by the tags_table function
    
    :Return:     - a polars DataFrame of absolute frequencies, normalized frequencies (per million tokens) and ranges for both corpora, as well as keyness values as calculated by log-likelihood and effect size as calculated by Log Ratio.


corpus_analysis.tag_ruler(tokens_table: pl.DataFrame, doc_id: Union[str, int], count_by='pos') -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Retrieve spans of tags to facilitate tag highligting in a single text.

    :Parameters: - **tokens_table** - A polars DataFrame as generated by the docuscope_parse function
    :Parameters: - **doc_id** - A document name or an integer representing the index of a document id
    :Parameters: - **count_by** - One of 'pos' or 'ds' for aggregating tokens
    
    :Return:     - A polars DataFrame including all tokens, tags, tags start indices, and tag end indices


corpus_utils
---------------

Utility functions for working with text data.

corpus_utils.get_text_paths(directory: str, recursive=False) -> List:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Gets a list of full paths for all files and directories in the given directory.

    :Parameters: - **directory** - A string represting a path to directory.
    :Parameters: - **recursive** - Whether or not to recursively search through subdirectories.
    
    :Return:     - A list of paths to plain text (TXT) files.


corpus_utils.readtext(paths: List) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Read in text (TXT) files from a list of paths into a polars DataFrame with 'doc_id' and 'text' columns.

    :Parameters: - **paths** - A list of strings representing paths to plain text (TXT) files.
    
    :Return:     - A polars DataFrame with 'doc_id' and 'text' columns.


corpus_utils.corpus_from_folder(directory: str) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A convenience function combining get_text_paths and readtext to generate a polars DataFrame formatted for docuscope_parse.

    :Parameters: - **directory** - A string representing the path to a directory of text (TXT) files to be processed.
    
    :Return:     - A polars DataFrame with 'doc_id' and 'text' columns.


corpus_utils.dtm_simplify(dtm: pl.DataFrame) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A function for aggregating part-of-speech tags into more general lexical categories returning the equivalent of the tags_dtm function.

    :Parameters: - **dtm** - A document-term-matrix with a doc_id column.
    
    :Return:     - A polars DataFrame of absolute frequencies, normalized frequencies(per million tokens) and ranges.
    


corpus_utils.freq_simplify(frequency_table: pl.DataFrame) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
A function for aggregating part-of-speech tags into more general lexical categories returning the equivalent of the frequency_table function.

    :Parameters: - **frequency_table** - A frequency table.
    
    :Return:     - A polars DataFrame of token counts.


corpus_utils.tags_simplify(dtm: pl.DataFrame) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A function for aggregating part-of-speech tags into more general lexical categories returning the equivalent of the tags_table function.

    :Parameters: - **dtm** - A document-term-matrix with a doc_id column
    
    :Return:     - A polars DataFrame of absolute frequencies, normalized frequencies(per million tokens) and ranges.


corpus_utils.dtm_to_coo(dtm: pl.DataFrame) -> coo_matrix:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A function for converting a tags dtm to a COOrdinate format.

    :Parameters: - **dtm** - A document-term-matrix with a doc_id column
    
    :Return:     - A COOrdinate format matrix, an index of document ids, and a list of variable names.


corpus_utils.from_tmtoolkit(tmtoolkit_corpus) -> pl.DataFrame:
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A simple wrapper for coverting a tmtoolkit corpus to a polars DataFrame.

    :Parameters: - **tmtoolkit_corpus** - A tmtoolkit corpus.
    
    :Return:     - A polars DataFrame formatted for further process in docuscospacy.


